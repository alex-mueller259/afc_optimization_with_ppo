# AFC optimization with PPO
### Optimizing active flow control parameters using reinforcement learning with proximal policy optimization (PPO)

This is the code that was used to obtain measurement data and to run the PPO algorithm as explained in the paper "*Optimizing pulsed blowing parameters for active separation control in a one-sided diffuser using reinforcement learning*" by MÃ¼ller et al. that was presented at the DGLR STAB-Symposium held in Regensburg (Nov 13 - Nov 14 2024). It is currently under consideration for publication in the conference proceedings.
The pre-published version can be found on Arxiv. https://arxiv.org/abs/2412.07480

Additional discussions and results are presented in the Master's thesis "*Optimizing the pulsed blowing parameters for active separation control with reinforcement learning*" that is included in the repository.

The PPO algorithm is based on the paper "*Proximal Policy Optimization Algorithms*" by Schulman et al.  
https://arxiv.org/abs/1707.06347

The code is derived from existing PPO implementations in Python.  
https://github.com/henanmemeda/RL-Adventure-2/tree/master?tab=readme-ov-file  
https://github.com/philtabor/Youtube-Code-Repository/tree/master/ReinforcementLearning/PolicyGradient/PPO/torch
